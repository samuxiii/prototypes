{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pong.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "uASDXzVGNu7V",
        "colab_type": "code",
        "outputId": "70256a57-58ec-428c-cb43-c66d9a65995b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "!pip install gym\n",
        "!pip install â€œgym[atari]\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `\"'\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "966byywKZ0Br",
        "colab_type": "code",
        "outputId": "19ec9833-4e4b-4d8e-fe53-7ad65521deb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LkvaAmVKaWDl",
        "colab_type": "code",
        "outputId": "f13608d0-9400-47e5-fd6e-0877eadfc31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "TaW9fBcvxE0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.memory = []\n",
        "        self.epsilon = 1.0 #exploration rate\n",
        "        self.model = self.__model()\n",
        "\n",
        "    def __model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(units=200,input_dim=40*40, activation='relu'))\n",
        "        model.add(Dense(units=2, activation='sigmoid'))\n",
        "        #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=0.01, decay=0.01))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        #store in memory the different states, actions, rewards...\n",
        "        self.memory.append( (state, action, reward, next_state, done) )\n",
        "\n",
        "    def replay(self, win):\n",
        "        #fit model from memory\n",
        "        gamma = 0.5 #importance of the next reward\n",
        "        max_batch_size = 512\n",
        "\n",
        "        #take care the memory could be big, so using minibatch\n",
        "        minibatch = random.sample(self.memory, min(max_batch_size, len(self.memory)))\n",
        "        list_x_batch, list_y_batch = [], []\n",
        "        num_steps = len(minibatch)\n",
        "\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "\n",
        "            '''re-check dimesions of array to avoid this evaluation'''\n",
        "            if state.ndim != 2:\n",
        "              continue\n",
        "              \n",
        "            target = self.model.predict(state)[0]\n",
        "\n",
        "            if not done: #calculate discounted reward\n",
        "                action_values = self.model.predict(next_state)[0]\n",
        "                #following the formula of action-value expectation\n",
        "                reward = reward + gamma * np.amax(action_values)\n",
        "            #else: #PROVISIONAL\n",
        "            #    map(lambda x:x+1, list_y_batch) #!! updating previous actions\n",
        "\n",
        "            #customize the obtained reward with the calculated\n",
        "            reg = (num_steps/(num_steps+1))\n",
        "            end_reward =  reg if win else (reg-1)\n",
        "            target[action] = reward + end_reward\n",
        "\n",
        "            #append\n",
        "            list_x_batch.append(state)\n",
        "            list_y_batch.append(target)\n",
        "\n",
        "        #train the model\n",
        "        x_batch = np.vstack(list_x_batch)\n",
        "        y_batch = np.vstack(list_y_batch)\n",
        "        self.model.fit(x_batch, y_batch, verbose=0)\n",
        "\n",
        "        #decrease exploration rate\n",
        "        if self.epsilon > 0.01:\n",
        "            self.epsilon *= 0.997\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "        if self.epsilon > np.random.rand():\n",
        "            return random.randint(0,1)\n",
        "\n",
        "        #predict the action to do\n",
        "        action_values = self.model.predict(state)[0]\n",
        "\n",
        "        return np.argmax(action_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFceIcedNW21",
        "colab_type": "code",
        "outputId": "8e89953c-815e-490c-94dc-774ee78bfcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7936
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "from time import sleep\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def prepro(I):\n",
        "# prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::4,::4,0] # downsample by factor of 4\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "\n",
        "# code for the two only actions in Pong\n",
        "UP_ACTION = 2\n",
        "DOWN_ACTION = 3\n",
        "\n",
        "# initializing our environment\n",
        "env = gym.make(\"Pong-v0\")\n",
        "\n",
        "# beginning of an episode\n",
        "observation = env.reset()\n",
        "observation = prepro(observation).reshape(1, -1)\n",
        "\n",
        "# model weights\n",
        "h5file = \"weights.h5\"\n",
        "\n",
        "# agent\n",
        "agent = Agent()\n",
        "\n",
        "# get model\n",
        "if os.path.exists(h5file):\n",
        "    agent.model.load_weights(h5file)\n",
        "\n",
        "\n",
        "# training conf\n",
        "training = True\n",
        "#x_train, y_train, rewards = [], [], []\n",
        "#reward_sum = 0\n",
        "\n",
        "# main loop\n",
        "for i in range(10000000):\n",
        "    # predict action\n",
        "    '''re-check dimesions of array to avoid this evaluation'''\n",
        "    if observation.ndim != 2:\n",
        "      movement = UP_ACTION\n",
        "    else:\n",
        "      action = agent.act(observation)\n",
        "      movement = UP_ACTION if action==0 else DOWN_ACTION\n",
        "\n",
        "    # do one step\n",
        "    next_observation, reward, done, info = env.step(movement)\n",
        "\n",
        "    #row vector\n",
        "    ##print(\"reward:{} done:{} info:{}\".format(reward, done, info))\n",
        "    next_observation = prepro(next_observation).reshape(1, -1)\n",
        "    #next_observation = next_observation.reshape(1, -1)\n",
        "\n",
        "    #save the current observation\n",
        "    agent.remember(observation, action, reward, next_observation, done)\n",
        "\n",
        "    #update state\n",
        "    observation = next_observation\n",
        "\n",
        "    if done:\n",
        "        if training:\n",
        "            win = True if reward == 1 else False\n",
        "            agent.replay(win)\n",
        "            agent.model.save_weights(h5file)\n",
        "            \n",
        "        if reward==1:\n",
        "          print(\"Win!!\")\n",
        "          break\n",
        "        else:\n",
        "          print(\"Lose..\")\n",
        "          \n",
        "        print(info)\n",
        "        observation = env.reset()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n",
            "Lose..\n",
            "{'ale.lives': 0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6b8956c0d90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6202774c2c34>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, win)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#calculate discounted reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0maction_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;31m#following the formula of action-value expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-xUqy6gmRMnQ",
        "colab_type": "code",
        "outputId": "d73499a2-74b2-4541-a316-2d09d2158ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "!ls weights.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}